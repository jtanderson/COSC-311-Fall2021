{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\"\"\"\n",
    "A \"from-scratch\" neural network implementation for educational purposes.\n",
    "This version is a simple binary classififer. It allows the user to incrementally\n",
    "train the network, displaying the resulting decision boundary and full density.\n",
    "The training data is hard-coded, but there is also a loop to allow more\n",
    "custom training data. We initialize the weights to be drawn from a standard\n",
    "Gaussian distribution.\n",
    "\n",
    "A crude diagram of a NN with two hidden layers and 2-dimensional inputs.\n",
    "The final layer is returned as a weighted sum, passed through a final\n",
    "sigmoid function. This scalar will determine which class to assign to the\n",
    "input point.\n",
    "\n",
    "x1--O---O\n",
    "  \\ / \\ / \\ \n",
    "   x   x   O --\n",
    "  / \\ / \\ /\n",
    "x2--O---O\n",
    "\n",
    "@author: Joseph Anderson <jtanderson@salisbury.edu>\n",
    "@date:   28 May 2019\n",
    "\n",
    "Exercise 1: vectorize more of the operations, combine the input, output, and\n",
    "hidden layers into single matrices. \n",
    "Exercise 2: Adapt the model to learn more than two classes\n",
    "Exercise 3: Use \"convolutional\" or \"recurrent\" neuron architectures\n",
    "Exercise 4: Turn into a \"generative\" model, to generate typical examples\n",
    "from either of the two classes\n",
    "Exercise 5: Parallelize!\n",
    "\n",
    "\n",
    "For motivation/explanation, see, for example:\n",
    "https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/\n",
    "\"\"\"\n",
    "\n",
    "# The dimensionality of the input data\n",
    "dim = 2 \n",
    "\n",
    "# The number of hidden layers\n",
    "num_layers = 1\n",
    "\n",
    "# The size of each hidden layer\n",
    "layer_size = 2\n",
    "\n",
    "# The step size used in gradient descent\n",
    "rate = 0.1\n",
    "\n",
    "bias = False\n",
    "\n",
    "# add a dimension for bias\n",
    "if bias:\n",
    "    dim += 1\n",
    "\n",
    "# X holds N-by-d samples\n",
    "#   - N is number of samples\n",
    "#   - d is dimension\n",
    "X = np.empty((0,dim), float)\n",
    "\n",
    "# Y holds N labels of -1 or 1\n",
    "Y = np.array([])\n",
    "\n",
    "# input weights. Row i is the array of weights applied to x_i\n",
    "w_in = np.random.standard_normal((dim,layer_size))\n",
    "\n",
    "# \"Tensor\" (3-dim array) of hidden-layer output weights. \n",
    "# w_hidden[lay][i][j] is the weight between lay node i and lay+1 node j\n",
    "w_hidden = np.random.standard_normal((num_layers-1, layer_size, layer_size))\n",
    "\n",
    "# output weights, comes from last layer\n",
    "w_out = np.random.standard_normal((1,layer_size))\n",
    "\n",
    "# Use the standard sigmoid function. Another option is arctan, etc.\n",
    "def sigmoid(arr):\n",
    "    return 1/(1+np.exp(-1*arr))\n",
    "\n",
    "# The derivative of the sigmoid function.\n",
    "# Check this by hand to see how convenient it is :)\n",
    "def sigmoid_deriv(arr):\n",
    "    return sigmoid(arr) * (1 - sigmoid(arr))\n",
    "\n",
    "# The squared error between to vectors/scalars\n",
    "def msqerr(pred, ans):\n",
    "    return np.sum((pred-ans)**2)/2\n",
    "\n",
    "def reset():\n",
    "    w_in = np.random.standard_normal((dim,layer_size))\n",
    "    w_hidden = np.random.standard_normal((num_layers-1, layer_size, layer_size))\n",
    "    w_out = np.random.standard_normal((1,layer_size))\n",
    "    return (w_in, w_hidden, w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward_step takes the weights of the network and an input point,\n",
    "returning the scalar output of the network, along with a matrix\n",
    "which is a record of the output of each intermediate node during\n",
    "the computation. This is needed for training and verification.\n",
    "\n",
    "Arguments:\n",
    "inw is the dim-by-h matrix of input weights to the first layer\n",
    "outw is the h-by-1 array of weights from the last hidden layer to the output node\n",
    "hiddenw is the num_layers-by-layer_size-by-layer_size matrix of weights between each layer\n",
    "    hidden[i] has the weights from i to i+1\n",
    "    hidden[i][j] is the array of weights into node j of layer i+1\n",
    "data is 1-by-dim row vector\n",
    "\n",
    "Returns:\n",
    "scalar value coming out of the output node\n",
    "outs is layers-by-layer_size to store the output of each node\n",
    "\"\"\"\n",
    "def forward_step(inw, outw, hiddenw, data):\n",
    "    outs = np.array([sigmoid(data @ inw)]) # 1-by-dim times dim-by-h\n",
    "    for i in range(1,num_layers):\n",
    "        # i-1 here because w[i] is output weights\n",
    "        # get the output of the last layer (sig of x) and weight it into this layer\n",
    "        ins = outs[-1] @ hiddenw[i-1]  # 1-by-h times h-by-h\n",
    "        outs = np.append(outs, [sigmoid(ins)], axis=0)\n",
    "\n",
    "    # last row of outs now holds the weighted output of the last hidden layer\n",
    "    ret = sigmoid(outs[-1] @ outw.T)\n",
    "    return ret[0], outs\n",
    "\n",
    "\"\"\"\n",
    "backprop analyzes how wrong the network was at predicting a given label,\n",
    "then uses the magnitude of the error to perform gradient descent on the\n",
    "edge weights throughout the network. Check this with the chain rule\n",
    "of the error function! It tracks the change in error with respect to weights,\n",
    "inputs, and outputs of every node in the network\n",
    "\n",
    "inw: dim-by-layer_size\n",
    "    weights of the input nodes\n",
    "outw: 1-by-layer_size\n",
    "    weights to the output node\n",
    "hiddenw: num_layers-1 x layer_size x layer_size\n",
    "    hiddenw[lay][i][j] is the weight between lay node i and lay+1 node j\n",
    "    a column is all input weights to that node\n",
    "outputs: num_layers x layer_size\n",
    "    record of every node's output from the forward pass\n",
    "pred: scalar predicted output\n",
    "data: the input data point\n",
    "label: scalar true output\n",
    "\"\"\"\n",
    "def backprop(inw, outw, hiddenw, outputs, pred, data, label):\n",
    "    dEyo = pred - label # scalar\n",
    "    dExo = dEyo * sigmoid_deriv(np.dot(outputs[-1], outw[0])) # scalar\n",
    "    dEwo =  dExo * outputs[-1] #np.zeros((1, layer_size)) # out\n",
    "    \n",
    "    # hidden layer derivatives setup\n",
    "    dEwh = np.zeros((num_layers-1, layer_size, layer_size))\n",
    "    dExh = np.zeros((num_layers, layer_size))\n",
    "    dEyh = np.zeros((num_layers, layer_size))\n",
    "    \n",
    "    # need to do output layer first, not a matrix product\n",
    "    dEyh[-1] = outw * dExo # 1-by-h times scalar\n",
    "    dExh[-1] = dEyh[-1] * sigmoid_deriv(dExo)\n",
    "\n",
    "    for i in range(num_layers-2,-1,-1):\n",
    "        # i-1 to get the inputs to layer i\n",
    "        x = outputs[i-1] @ hiddenw[i-1] # 1-by-h times h-by-h\n",
    "        dExh[i] = dEyh[i] * sigmoid_deriv(x) # 1-by-h\n",
    "        dEwh[i] = outputs[i-1] * dExh[i]\n",
    "        if i > 0:\n",
    "            # prep the next layer\n",
    "            dEyh[i-1] = hiddenw[i] @ dExh[i].T # h-by-h times h-by-1\n",
    "\n",
    "    #dEwi = outputs[0] * dEyh[0] # take care of the input layer, again\n",
    "                                # not a matrix product\n",
    "    data = numpy.array([data])\n",
    "    dEwi = np.matlib.repmat(data.T, 1, layer_size) * np.matlib.repmat(dExh[0], dim, 1)  # dim-by-h broadcast dim-by-h\n",
    "\n",
    "\n",
    "    # adjust the hiden layer weights accoriding to the error.\n",
    "    # Check to see that this follows gradient descent!\n",
    "    hiddenw = hiddenw - rate * dEwh\n",
    "    inw = inw - rate * dEwi\n",
    "    outw[0] = outw[0] - rate * dEwo\n",
    "\n",
    "    # return the new weights\n",
    "    return inw, outw, hiddenw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rounds(train_x, train_y, num_rounds, w_in, w_out, w_hidden):\n",
    "    # Set up the plotting\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.ion()\n",
    "    fig.show()\n",
    "    fig.canvas.draw()\n",
    "    plt.axis([-4,4,-4,4])\n",
    "    ax.axis([-4,4,-4,4])\n",
    "    \n",
    "    # iterate as long as we're told\n",
    "    # For each epoch, it would be helpful to print the total \"loss\" -- the error\n",
    "    # across the whole training set.\n",
    "    # Often, one might choose a loss threshold (say, < 0.0001) and simply train until\n",
    "    # the loss is smaller\n",
    "    for i in range(1,num_rounds+1):\n",
    "        # iterate each data point\n",
    "        loss = 0\n",
    "        for j in range(0,train_x.shape[0]):\n",
    "            dat = train_x[j]\n",
    "            if bias:\n",
    "                dat = np.append(train_x[j], [1])\n",
    "\n",
    "            # get the prediction for the point, using the current weights (model)\n",
    "            pred, vals = forward_step(w_in, w_out, w_hidden, dat)\n",
    "            # adjust the weights (model) to account for whether we're incorrect\n",
    "            w_in, w_out, w_hidden = backprop(w_in, w_out, w_hidden, vals, pred, dat, train_y[j])\n",
    "            loss += abs(pred - train_y[j])**2\n",
    "    print(\"Current loss: \" + str(loss))\n",
    "\n",
    "    ax.clear()\n",
    "    p_x, p_y = (train_x[np.where(train_y==1)]).T\n",
    "    ax.plot(p_x, p_y, 'ob')\n",
    "    p_x, p_y = (train_x[np.where(train_y==-1)]).T\n",
    "    ax.plot(p_x, p_y, 'or')\n",
    "    ax.axis([-4,4,-4,4])\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the decision area contours\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up some arrays to compute the contours, store in an image\n",
    "    im_x = np.arange(-4,4,0.1)\n",
    "    im_y = np.arange(-4,4,0.1)\n",
    "    im_X, im_Y = np.meshgrid(im_x, im_y)\n",
    "\n",
    "    # values\n",
    "    im_Z = [] # np.zeros(im_X.shape)\n",
    "\n",
    "    # TODO: use list comp, zipping, and mapping for this, for-loop is slow\n",
    "    for j in range(len(im_X)): # walk over rows\n",
    "        for i in range(len(im_X[0])): # walk over columns\n",
    "            # Get the value for \n",
    "            # swap i and j to compensate for grid layout\n",
    "            dat = np.array([im_X[j][i], im_Y[j][i]]) # without bias\n",
    "            if(bias):\n",
    "                dat = np.append(dat, [1]) # add bias input\n",
    "            res, _ = forward_step(w_in, w_out, w_hidden, dat) # with bias\n",
    "            im_Z.append(res)\n",
    "\n",
    "    im_Z = numpy.array(im_Z).reshape(im_X.shape)\n",
    "\n",
    "    # see the matplotlib contourf documentation\n",
    "    cset1 = plt.contourf(im_X, im_Y, im_Z, cmap='RdBu', alpha=0.5)\n",
    "    fig.canvas.draw()\n",
    "    return (w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hard-code more points, or adjust as needed.\n",
    "Check to make sure the structure matches the assumptions above\n",
    "\"\"\"\n",
    "\n",
    "# Input data, linearly separable classes\n",
    "# Even for this setup, the network can have a tough time getting a good model!\n",
    "# Sometimes you can even hit a \"local\" minimum where more training doesn't help,\n",
    "# we need to perturb things a bit or get more data.\n",
    "X = np.array(\n",
    "    [\n",
    "        [ 0.2, 2.2 ],\n",
    "        [ -1.9, -0.3],\n",
    "        [ 1, -1],\n",
    "        #[ -1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The labels\n",
    "Y = np.array([1, 1, -1])\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# To run and get updated weights:\n",
    "# w_in, w_out, w_hidden = train_rounds(X, Y, epochs, w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in, w_hidden, w_out = reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtanderson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 2.8366516770081316\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_in, w_out, w_hidden = train_rounds(X, Y, 1, w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 2.96781358041\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_in, w_out, w_hidden = train_rounds(X, Y, 1, w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
